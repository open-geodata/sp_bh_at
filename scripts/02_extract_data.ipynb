{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c234657b-c5ca-4fe9-a257-b5b6a43a6fa1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Introdução\n",
    "\n",
    "Extrai os arquivos baixados em .rar e transforma em .gpkg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869dd616-30e1-46c5-b9cd-83c272463a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install rarfile --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddc11c-3ec0-4786-bedb-7dc0837a4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "import time\n",
    "import shutil\n",
    "import warnings\n",
    "import urllib.request\n",
    "import geopandas as gpd\n",
    "from rarfile import RarFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e5179-bf9f-4b32-b26f-898a60a20c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6119dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3d562",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read File URLS\n",
    "input_file = input_path / 'urls.txt'\n",
    "\n",
    "# Read File\n",
    "with open(input_file, encoding='utf-8') as f:\n",
    "    lines = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "# Loop\n",
    "for line in lines:\n",
    "    url = urllib.parse.unquote(line)\n",
    "    #print(url)\n",
    "\n",
    "    # Filename\n",
    "    filename = Path(url).name.replace('-', ' ')\n",
    "    filepath = input_path_brutos / filename\n",
    "    print(f'> {filename}')\n",
    "\n",
    "    # Download\n",
    "    my_headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    req = urllib.request.Request(line, headers=my_headers)\n",
    "    with urllib.request.urlopen(req) as r, open(filepath, 'wb') as out_file:\n",
    "        shutil.copyfileobj(r, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb74ea",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Files\n",
    "list_files = list(input_path_brutos.rglob('*.rar'))\n",
    "\n",
    "# Results\n",
    "print(f'Temos {len(list_files)} arquivos .rar')\n",
    "list_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d46db",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ac755-7feb-4b6b-ae04-e37e2fcdb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unrar_files(rar_filepath, output_path):\n",
    "    # Unrar data\n",
    "    with RarFile(rar_filepath) as rarObj:\n",
    "        rarObj.extractall(output_path)\n",
    "\n",
    "    # Se extrair pasta, move conteudo da pasta    \n",
    "    list_files = list(output_path.rglob('*'))\n",
    "    for file in list_files:\n",
    "        # a = file.relative_to(output_path)\n",
    "        if file.is_file():\n",
    "            try:\n",
    "                shutil.move(file, output_path)\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e20306",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = input_path / 'temp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700a687-c310-41f3-a330-029b6b088cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_geodata(gdf, output_path, filename):\n",
    "    gdf.to_file(\n",
    "        output_path / 'comite_alto_tiete.gpkg',\n",
    "        layer=f'{filename}',\n",
    "        driver='GPKG'\n",
    "    )\n",
    "\n",
    "    gdf.to_file(\n",
    "        output_path / f'{filename}.gpkg',\n",
    "        layer=f'{filename}',\n",
    "        driver='GPKG'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf63eb-349d-4133-b3df-4f491d32a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_path(path, msg):\n",
    "    try:\n",
    "        os.chmod(path, 0o777)\n",
    "        shutil.rmtree(\n",
    "            path,\n",
    "            onerror=print(msg),\n",
    "            ignore_errors=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_thrash(path):\n",
    "    if path.is_dir():\n",
    "        list_files = list(path.rglob('*'))\n",
    "        for f in list_files:\n",
    "            if f.is_file():\n",
    "                os.chmod(f , stat.S_IWRITE)\n",
    "                os.remove(f)\n",
    "            if f.is_dir():\n",
    "                clean_thrash(f)\n",
    "                os.chmod(f , stat.S_IWRITE)            \n",
    "                f.unlink()\n",
    "    else:\n",
    "        print('Não é dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d084c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_path(temp_path, 'dds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b05f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_thrash(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb925357-4ac5-4cd8-b837-1c61dfca2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_files:\n",
    "    print('-'*40)\n",
    "    print(f'{file}')\n",
    "    rar_filepath = file\n",
    "\n",
    "    # Delete Path\n",
    "    delete_path(temp_path, 'Erro pra Deletar!')\n",
    "    clean_thrash(temp_path)\n",
    "\n",
    "    # Set path to work\n",
    "    temp_path = input_path / 'temp'\n",
    "    temp_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Unrar data\n",
    "    unrar_files(rar_filepath, temp_path)\n",
    "\n",
    "    # Get list of shapefiles\n",
    "    list_shps = list(temp_path.rglob('*.shp'))\n",
    "\n",
    "    if len(list_shps) == 1:\n",
    "        # Shapefile\n",
    "        shp_file = list_shps[0]\n",
    "        print(shp_file)\n",
    "\n",
    "        # Set name for output\n",
    "        shp_file_out = shp_file.stem.lower()\n",
    "        print(shp_file_out)\n",
    "\n",
    "        # Read Shapefile\n",
    "        if shp_file_out == '45_subbacias':\n",
    "            gdf = gpd.read_file(shp_file, encoding='ISO-8859-1')\n",
    "            gdf = gdf.to_crs(epsg=4326)\n",
    "            dict_fix = {\n",
    "                'CrÃ\\xadtica': 'Crítica',\n",
    "                'NÃ£o CrÃ\\xadtica': 'Não Crítica',\n",
    "                'Sem ClassificaÃ§Ã£o': 'Sem Classificação'\n",
    "            }\n",
    "            gdf.replace(\n",
    "                {\n",
    "                    'Crit_IQA': dict_fix,\n",
    "                    'Crit_Uso': dict_fix,\n",
    "                    'IAP': dict_fix,\n",
    "                    'IVA': dict_fix,\n",
    "                    'OD': dict_fix,\n",
    "                },\n",
    "                inplace=True\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            gdf = gpd.read_file(temp_path / shp_file)\n",
    "            gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "        # Write data\n",
    "        write_geodata(gdf, output_path_gpkg, shp_file_out)\n",
    "\n",
    "        # Delete Path\n",
    "        delete_path(temp_path, 'Erro pra Deletar!')\n",
    "        clean_thrash(temp_path)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('Erro: Lista de shapes tem mais de um!')\n",
    "        print(list_shps)\n",
    "\n",
    "# Results\n",
    "print('Fimmmm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_path(temp_path, 'Erro pra Deletar!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc2eba1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Convert 7zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d65f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_geodata import converts\n",
    "\n",
    "converts.files.convert_to_7zip(output_path_gpkg, output_path_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fc1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pablocarreira-py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "397a8db9a99587ebc9659e575e97c3dbc03b7cdbd9bc181d706cc19eab1087ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
